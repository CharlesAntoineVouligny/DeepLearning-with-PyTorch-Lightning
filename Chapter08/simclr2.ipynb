{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xur_WQAEr3p4"
   },
   "outputs": [],
   "source": [
    "pip install pytorch-lightning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4Awa2Wy4sB1y"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import urllib.request\n",
    "from copy import deepcopy\n",
    "from urllib.error import HTTPError\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import pytorch_lightning as pl\n",
    "import seaborn as sns\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as DataLoader\n",
    "\n",
    "from IPython.display import set_matplotlib_formats\n",
    "from pytorch_lightning.callbacks import LearningRateMonitor, ModelCheckpoint\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint\n",
    "from pytorch_lightning.callbacks import Callback\n",
    "\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "import torchvision.models as models\n",
    "from torchvision import datasets\n",
    "from torchvision.datasets import STL10\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "\n",
    "from torch.optim import Adam\n",
    "\n",
    "import numpy as np\n",
    "from torch.optim.lr_scheduler import OneCycleLR\n",
    "\n",
    "import zipfile\n",
    "from PIL import Image\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QIQPPJM5sKKO"
   },
   "outputs": [],
   "source": [
    "print(torch.__version__, torchvision.__version__, pl.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bbOa0l0vsPdf"
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "NUM_WORKERS = os.cpu_count()\n",
    "print(\"Device:\", device)\n",
    "print(\"Number of workers:\", NUM_WORKERS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1phcH-XZsfT_"
   },
   "outputs": [],
   "source": [
    "pl.seed_everything(96)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-g10hARWsk-L"
   },
   "outputs": [],
   "source": [
    "class DataAugTransform:\n",
    "    def __init__(self, base_transforms, n_views=2):\n",
    "        self.base_transforms = base_transforms\n",
    "        self.n_views = n_views\n",
    "\n",
    "    def __call__(self, x):\n",
    "        return [self.base_transforms(x) for i in range(self.n_views)]\n",
    "augmentation_transforms = transforms.Compose(\n",
    "    [\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.RandomResizedCrop(size=96),\n",
    "        transforms.RandomApply([transforms.ColorJitter(brightness=0.8, contrast=0.8, saturation=0.8, hue=0.1)], p=0.8),\n",
    "        transforms.RandomGrayscale(p=0.2),\n",
    "        #transforms.GaussianBlur(kernel_size=9),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.5,), (0.5,)),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1Aq90Tz1sqb9"
   },
   "outputs": [],
   "source": [
    "# Path to the folder where the datasets are/should be downloaded (e.g. CIFAR10)\n",
    "DATASET_PATH = os.environ.get(\"PATH_DATASETS\", \"bookdata/\")\n",
    "# Path to the folder where the pretrained models are saved\n",
    "CHECKPOINT_PATH = os.environ.get(\"PATH_CHECKPOINT\", \"booksaved_models/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yMHkUde1suhU"
   },
   "outputs": [],
   "source": [
    "unlabeled_data = STL10(\n",
    "    root=DATASET_PATH,\n",
    "    split=\"unlabeled\",\n",
    "    download=True,\n",
    "    transform=DataAugTransform(augmentation_transforms, n_views=2),\n",
    ")\n",
    "train_data_contrast = STL10(\n",
    "    root=DATASET_PATH,\n",
    "    split=\"train\",\n",
    "    download=True,\n",
    "    transform=DataAugTransform(augmentation_transforms, n_views=2),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "709Zg556sxlr"
   },
   "outputs": [],
   "source": [
    "# Visualize some examples\n",
    "pl.seed_everything(96)\n",
    "NUM_IMAGES = 20\n",
    "imgs = torch.stack([img for idx in range(NUM_IMAGES) for img in unlabeled_data[idx][0]], dim=0)\n",
    "img_grid = torchvision.utils.make_grid(imgs, nrow=10, normalize=True, pad_value=0.9)\n",
    "img_grid = img_grid.permute(1, 2, 0)\n",
    "\n",
    "plt.figure(figsize=(20, 10))\n",
    "#plt.title(\"Augmented image examples of the STL10 dataset\")\n",
    "plt.imshow(img_grid)\n",
    "plt.axis(\"off\")\n",
    "plt.show()\n",
    "#plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Vo23ZGOls0IG"
   },
   "outputs": [],
   "source": [
    "class NTXentLoss(torch.nn.Module):\n",
    "\n",
    "    def __init__(self, batch_size, temperature, use_cosine_similarity):\n",
    "        super(NTXentLoss, self).__init__()\n",
    "        self.batch_size = batch_size\n",
    "        self.temperature = temperature\n",
    "        self.softmax = torch.nn.Softmax(dim=-1)\n",
    "        self.mask_samples_from_same_repr = self._get_correlated_mask()\n",
    "        self.similarity_function = self._get_similarity_function(use_cosine_similarity)\n",
    "        self.criterion = torch.nn.CrossEntropyLoss(reduction=\"sum\")\n",
    "\n",
    "    def _get_similarity_function(self, use_cosine_similarity):\n",
    "        if use_cosine_similarity:\n",
    "            self._cosine_similarity = torch.nn.CosineSimilarity(dim=-1)\n",
    "            return self._cosine_simililarity\n",
    "        else:\n",
    "            return self._dot_simililarity\n",
    "\n",
    "    def _get_correlated_mask(self):\n",
    "        diag = np.eye(2 * self.batch_size)\n",
    "        l1 = np.eye((2 * self.batch_size), 2 * self.batch_size, k=-self.batch_size)\n",
    "        l2 = np.eye((2 * self.batch_size), 2 * self.batch_size, k=self.batch_size)\n",
    "        mask = torch.from_numpy((diag + l1 + l2))\n",
    "        mask = (1 - mask).type(torch.bool)\n",
    "        return mask\n",
    "\n",
    "    @staticmethod\n",
    "    def _dot_simililarity(x, y):\n",
    "        v = torch.tensordot(x.unsqueeze(1), y.T.unsqueeze(0), dims=2)\n",
    "        # x shape: (N, 1, C)\n",
    "        # y shape: (1, C, 2N)\n",
    "        # v shape: (N, 2N)\n",
    "        return v\n",
    "\n",
    "    def _cosine_simililarity(self, x, y):\n",
    "        # x shape: (N, 1, C)\n",
    "        # y shape: (1, 2N, C)\n",
    "        # v shape: (N, 2N)\n",
    "        v = self._cosine_similarity(x.unsqueeze(1), y.unsqueeze(0))\n",
    "        return v\n",
    "\n",
    "    def forward(self, zis, zjs):\n",
    "        representations = torch.cat([zjs, zis], dim=0)\n",
    "\n",
    "        similarity_matrix = self.similarity_function(representations, representations)\n",
    "\n",
    "        # filter out the scores from the positive samples\n",
    "        l_pos = torch.diag(similarity_matrix, self.batch_size)\n",
    "        r_pos = torch.diag(similarity_matrix, -self.batch_size)\n",
    "        positives = torch.cat([l_pos, r_pos]).view(2 * self.batch_size, 1)\n",
    "\n",
    "        negatives = similarity_matrix[self.mask_samples_from_same_repr].view(2 * self.batch_size, -1)\n",
    "\n",
    "        logits = torch.cat((positives, negatives), dim=1)\n",
    "        logits /= self.temperature\n",
    "\n",
    "        labels = torch.zeros(2 * self.batch_size).long()\n",
    "        loss = self.criterion(logits, labels)\n",
    "\n",
    "        return loss / (2 * self.batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CrXvuQXJs4v7"
   },
   "outputs": [],
   "source": [
    "class ResNetSimCLR(nn.Module):\n",
    "\n",
    "    def __init__(self, base_model, out_dim, freeze=True):\n",
    "        super(ResNetSimCLR, self).__init__()\n",
    "        \n",
    "        # Number of input features into the last linear layer\n",
    "        num_ftrs = base_model.fc.in_features\n",
    "        # Remove last layer of resnet\n",
    "        self.features = nn.Sequential(*list(base_model.children())[:-1])\n",
    "        if freeze:\n",
    "            self._freeze()\n",
    "\n",
    "        # header projection MLP - for SimCLR \n",
    "        self.l1 = nn.Linear(num_ftrs, 2*num_ftrs)\n",
    "        self.l2_bn = nn.BatchNorm1d(2*num_ftrs)\n",
    "        self.l2 = nn.Linear(2*num_ftrs, num_ftrs)\n",
    "        self.l3_bn = nn.BatchNorm1d(num_ftrs)\n",
    "        self.l3 = nn.Linear(num_ftrs, out_dim)\n",
    "\n",
    "    def _freeze(self):\n",
    "        num_layers = len(list(self.features.children())) # 9 layers, freeze all but last 2\n",
    "        current_layer = 1\n",
    "        for child in list(self.features.children()):\n",
    "            if current_layer > num_layers-2:\n",
    "                for param in child.parameters():\n",
    "                    param.requires_grad = True\n",
    "            else:\n",
    "                for param in child.parameters():\n",
    "                    param.requires_grad = False\n",
    "            current_layer += 1\n",
    "\n",
    "    def forward(self, x):\n",
    "        h = self.features(x)\n",
    "        h = h.squeeze()\n",
    "\n",
    "        if len(h.shape) == 1:\n",
    "            h = h.unsqueeze(0)\n",
    "\n",
    "        x_l1 = self.l1(h)\n",
    "        x = self.l2_bn(x_l1)\n",
    "        x = F.selu(x)\n",
    "        x = self.l2(x)\n",
    "        x = self.l3_bn(x)\n",
    "        x = F.selu(x)\n",
    "        x = self.l3(x)\n",
    "        return h, x_l1, x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ITaO3RCAs-9s"
   },
   "outputs": [],
   "source": [
    "import yaml # Handles config file loading\n",
    "# Load config file\n",
    "config = '''\n",
    "batch_size: 128\n",
    "epochs: 100\n",
    "weight_decay: 10e-6\n",
    "out_dim: 256\n",
    "\n",
    "dataset:\n",
    "  s: 1\n",
    "  input_shape: (96,96,3)\n",
    "  num_workers: 2\n",
    "\n",
    "optimizer:\n",
    "  lr: 0.0001\n",
    "\n",
    "loss:\n",
    "  temperature: 0.05\n",
    "  use_cosine_similarity: True\n",
    "\n",
    "lr_schedule:\n",
    "  max_lr: .1\n",
    "  total_steps: 1500\n",
    "'''\n",
    "config = yaml.full_load(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SA_dFKUUtEEH"
   },
   "outputs": [],
   "source": [
    "class simCLR(pl.LightningModule):\n",
    "\n",
    "    def __init__(self, model, config, optimizer=Adam, loss=NTXentLoss):\n",
    "        super(simCLR, self).__init__()\n",
    "        # Config file (dictionary) to pass on parameters to each module: optimizer, loss, lr_schedule, \n",
    "        self.config = config\n",
    "\n",
    "        # Optimizer\n",
    "        self.optimizer = optimizer\n",
    "\n",
    "        # Model\n",
    "        self.model = model\n",
    "        \n",
    "        # Loss\n",
    "        self.loss = loss(self.config['batch_size'], **self.config['loss'])\n",
    "\n",
    "    # Prediction/inference\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "    # Sets up optimizer\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = self.optimizer(self.parameters(), **self.config['optimizer'])\n",
    "        scheduler = OneCycleLR(optimizer, **self.config[\"lr_schedule\"])\n",
    "        return [optimizer], [scheduler]\n",
    "\n",
    "    # Training loops\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        xis, xjs = x\n",
    "        ris, _, zis = self(xis)\n",
    "        rjs, _, zjs = self(xjs)\n",
    "\n",
    "        zis = F.normalize(zis, dim=1)\n",
    "        zjs = F.normalize(zjs, dim=1)\n",
    "\n",
    "        loss = self.loss(zis, zjs)\n",
    "        return loss\n",
    "\n",
    "    # Validation step\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        xis, xjs = x\n",
    "        ris, _, zis = self(xis)\n",
    "        rjs, _, zjs = self(xjs)\n",
    "\n",
    "        zis = F.normalize(zis, dim=1)\n",
    "        zjs = F.normalize(zjs, dim=1)\n",
    "\n",
    "        loss = self.loss(zis, zjs)\n",
    "        self.log('val_loss', loss)\n",
    "        return loss\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        loss = None\n",
    "        return loss\n",
    "\n",
    "def _get_model_checkpoint():\n",
    "    return ModelCheckpoint(\n",
    "        filepath=os.path.join(os.getcwd(),\"checkpoints\",\"best_val_models\"),\n",
    "        save_top_k = 3,\n",
    "        monitor=\"val_loss\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3sPITq9rtkrT"
   },
   "outputs": [],
   "source": [
    "train_loader = DataLoader.DataLoader(\n",
    "            unlabeled_data,\n",
    "            batch_size=128,\n",
    "            shuffle=True,\n",
    "            drop_last=True,\n",
    "            pin_memory=True,\n",
    "            num_workers=NUM_WORKERS,\n",
    "        )\n",
    "val_loader = DataLoader.DataLoader(\n",
    "            train_data_contrast,\n",
    "            batch_size=128,\n",
    "            shuffle=False,\n",
    "            drop_last=False,\n",
    "            pin_memory=True,\n",
    "            num_workers=NUM_WORKERS,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2nd5MVBQt2-8"
   },
   "outputs": [],
   "source": [
    "resnet = models.resnet50(pretrained=True)\n",
    "\n",
    "simclr_resnet = ResNetSimCLR(base_model=resnet, out_dim=config['out_dim'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ydp-18YCuAC0"
   },
   "outputs": [],
   "source": [
    "# Creates the simCLR model with the specified architecture from aboce\n",
    "model = simCLR(config=config, model=simclr_resnet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Oo5Wr_SBuEih"
   },
   "outputs": [],
   "source": [
    "# Initializes the model trainer\n",
    "trainer = pl.Trainer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "b5PdWygKuGkd"
   },
   "outputs": [],
   "source": [
    "# Fits the model\n",
    "trainer.fit(model, train_loader, val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nHa6aZQuu_f8"
   },
   "outputs": [],
   "source": [
    "# %tensorboard --logdir ../saved_models/tutorial17/tensorboards/SimCLR/"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "simclr2",
   "private_outputs": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
